{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6afb72-b246-452e-b367-5079623a4de3",
   "metadata": {},
   "source": [
    "<u> \n",
    "    \n",
    "# BERT Tokenization, Input Encoding, and Inference Demo \n",
    "\n",
    "</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d0200-7b0c-4330-8ac5-635860e0d0a8",
   "metadata": {},
   "source": [
    "<h3>\n",
    "I will start by installing my necessary transformers, dataset and library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a73eb2f-35f0-4a26-947e-f599986a6a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/alash-studios/venv/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: evaluate in /home/alash-studios/venv/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /home/alash-studios/venv/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/alash-studios/venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (0.31.2)\n",
      "Requirement already satisfied: packaging in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/alash-studios/venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/alash-studios/venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/alash-studios/venv/lib/python3.12/site-packages (from transformers[sentencepiece]) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/alash-studios/venv/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/alash-studios/venv/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.5.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/alash-studios/venv/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /home/alash-studios/venv/lib/python3.12/site-packages (from transformers[sentencepiece]) (5.27.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/alash-studios/venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/alash-studios/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/alash-studios/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/alash-studios/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/alash-studios/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/alash-studios/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/alash-studios/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/alash-studios/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/alash-studios/venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alash-studios/venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alash-studios/venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alash-studios/venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alash-studios/venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/alash-studios/venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/alash-studios/venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/alash-studios/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d221fad-9266-4163-82c3-f8b8042f476b",
   "metadata": {},
   "source": [
    "<h3> Now i wanna configure the bert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a43aa6a-f093-44e5-950b-23036b5a3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Building the config\n",
    "config = BertConfig()\n",
    "\n",
    "# Building the model from the config\n",
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d6055-f021-492a-81ab-3e84f3023c7b",
   "metadata": {},
   "source": [
    "<h3> Thank God seems like the configuration of the bert model was sucessful now i'm gonna get the config data by printing config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90037b95-3bde-4344-98cc-5c078cd63261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e90657-46b4-4530-acf4-2aa79cd196ec",
   "metadata": {},
   "source": [
    "<h3> Ok so now i have the data of the bert model configuration, i am going to be initializing the model now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ed0c69-4e0c-47ee-b302-45dfebc9f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "config = BertConfig()\n",
    "model = BertModel(config)\n",
    "\n",
    "# Model is randomly initialized!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684f454-6ff4-4e44-acd9-62294d88570f",
   "metadata": {},
   "source": [
    "<h3> My next plan is to load a pretrained model and then save it locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce5062b-d38b-4f96-8937-124e2a2a218d",
   "metadata": {},
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "model.save_pretrained(\"Documents/Jupyter Notebook/Pre-Trained Model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae613771-3195-42dd-b80d-66c9b9235c4c",
   "metadata": {},
   "source": [
    "<span style=\"background-color: yellow\">  Alasela Don't forget to load the model you have above, it is the last thing left for you to finish up the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31225026-11ea-4ddf-8f59-b8eee06ceb5c",
   "metadata": {},
   "source": [
    "<h3> Now i wanna get the token id for a seqence of texts, i will use simple texts so the tokens aren't to long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4499cf3b-b565-48a5-9fba-972c910aca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8968366-c8f3-4ecb-8619-2b791f19fdb2",
   "metadata": {},
   "source": [
    "<h3> Now i will try to manually encode so i can gain insigths on tokenization mechanics, this cell is not really important but anyhow i will still do it, just for the nolstalgia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c29b31fa-12c6-479f-bf17-b6e6deadf8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = [\n",
    "    [101, 7592, 999, 102],\n",
    "    [101, 4658, 1012, 102],\n",
    "    [101, 3835, 999, 102],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46e0bae-ca2f-43f0-9279-9bf4c1a2120e",
   "metadata": {},
   "source": [
    "<h3> Just wrote the seqence of texts in tokens. Now i am gonna pass the encoded tokens to tensor cause the bert model expects the data in tensors not python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fea236aa-013d-4d63-94cd-e0ff5527b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model_inputs = torch.tensor(encoded_sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1f8dfb-42e8-4152-931f-f925f94689b3",
   "metadata": {},
   "source": [
    "<h3> Now i am going to be feeding the inputs (encoded text) as outputs to the bert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "594f6aac-4e50-46e7-ab1b-7671bb20bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(model_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69167213-6180-47dc-9c83-cbda95b2c85e",
   "metadata": {},
   "source": [
    "<h3> Now i wanna load the autotokenizer so my text input is transformed to tokens that the bert model understands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "737ca9e1-6822-4bf3-9e5d-a1c4c2a1a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2978e-f074-4a3d-8a8b-298f668c026d",
   "metadata": {},
   "source": [
    "<h3> Now i wanna print the tokens and thier corresponding id's, in the encoded text dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de90acd2-b5dc-44d8-9fee-c0d962bdb4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(101, '[CLS]'), (7592, 'hello'), (999, '!'), (102, '[SEP]')]\n",
      "[(101, '[CLS]'), (4658, 'cool'), (1012, '.'), (102, '[SEP]')]\n",
      "[(101, '[CLS]'), (3835, 'nice'), (999, '!'), (102, '[SEP]')]\n"
     ]
    }
   ],
   "source": [
    "for seq in encoded_sequences:\n",
    "    tokens = tokenizer.convert_ids_to_tokens(seq)\n",
    "    print(list(zip(seq, tokens)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdea8c8-a6d1-4262-bcf5-3a26162c9e8a",
   "metadata": {},
   "source": [
    "# Voila I'm Done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
