{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8799f6a0-bb72-49b1-be3d-7625e8778d52",
   "metadata": {},
   "source": [
    "<u> \n",
    "\n",
    "# Word Based Tokenization and Rule-Based Sentiment Response\n",
    "\n",
    "</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44a21e-93d5-44ee-b9db-1e0a4a415313",
   "metadata": {},
   "source": [
    "Now i would be loading the autotokenizer to get the tokens of some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810aa26a-c9d5-4e9a-b933-376ddfc37c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c347ccf-99ba-4c64-8a4f-b00877dc17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ac940fc-7c11-4c14-b573-8312919fbc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer(\"I am an Alasela Babatunde an Aspiring Ai Engineer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27852b-d711-4801-b89e-b0c9199b34f7",
   "metadata": {},
   "source": [
    "Now i will be printing the tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c0057b-c34d-4260-b8c5-ca6b94b8d6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 2572, 2019, 21862, 11246, 2050, 14208, 8525, 13629, 2019, 22344, 9932, 3992, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5a2b3-aeae-4949-b05f-b669a31b9ec4",
   "metadata": {},
   "source": [
    "I have gotten the text's tokens now, let me see if i can add a rule based sentiment response. To do this i will start with importing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7b0651d-246e-41c0-b096-6ecbc14ce3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b200db4b-6a41-4395-90cc-b4aba58418f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61f83fa9dfc449cae6b2780b7f256fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(\"sentiment-analysis\", model=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aaa80f47-c301-48c1-a361-557c6d175d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"I am so happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "115d8259-acfb-4c80-b03e-a451d6b6f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classified_text = sentiment_classifier(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da7b73d1-353a-4bf8-a824-76255f8cef20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.524634063243866}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34f5be-ba78-4d0a-af4c-126599f135e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'label' == \"LABEL_0\":\n",
    "    print(\"That is cool\")\n",
    "else:\n",
    "    print(\"Sorry about that\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
